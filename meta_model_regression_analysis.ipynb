{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "from sklearn.metrics import (\n",
    "    explained_variance_score,\n",
    "    max_error,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    median_absolute_error,\n",
    ")\n",
    "from catboost import CatBoostRegressor\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_relavent_columns(df, column_names=None):\n",
    "    if column_names is None:\n",
    "        return df\n",
    "    return df[column_names]\n",
    "\n",
    "def encode_one_hot(df):\n",
    "    columnsToEncode = list(df.select_dtypes(include=['category','object']))\n",
    "    for col in columnsToEncode:\n",
    "        if len(df[col].unique()) < 100:\n",
    "            df = pd.concat([df,pd.get_dummies(df[col], prefix=[col])], axis=1)\n",
    "        df.drop(col,inplace=True,axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_to_numberic_selective(df):\n",
    "    columnsToEncode = list(df.select_dtypes(include=['float','int']))\n",
    "    for col in columnsToEncode:\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "def process_column_names_xgboost(df):\n",
    "    #XGboost has additional requirements on characters which can be in column names, so this removes the characters\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    df.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in df.columns.values]\n",
    "    return df\n",
    "'''\n",
    "def preprocessing_without_drop(df, target, column_names=None,bad_columns=None, apply_onehot=True, using_xgboost=True):\n",
    "    target_df=df[target]\n",
    "    df.drop(target, inplace=True, axis=1)\n",
    "    \n",
    "    df = keep_relavent_columns(df,column_names)\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    if apply_onehot:\n",
    "        df = encode_one_hot(df)\n",
    "        df = df.astype('float64')\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    else :\n",
    "        df = apply_to_numberic_selective(df)\n",
    "    if using_xgboost:\n",
    "        df = process_column_names_xgboost(df)\n",
    "    df_merged = pd.merge(df,target_df, how='inner', left_index=True, right_index=True)\n",
    "    return df_merged\n",
    "'''\n",
    "def preprocessing(df, target, column_names=None,bad_columns=None, apply_onehot=True, using_xgboost=True):\n",
    "    target_df=df[target]\n",
    "    df.drop(target, inplace=True, axis=1)\n",
    "    \n",
    "    df = keep_relavent_columns(df,column_names)\n",
    "    df = drop_bad_columns(df, bad_columns)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    if apply_onehot:\n",
    "        df = encode_one_hot(df)\n",
    "        df = df.astype('float64')\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    else :\n",
    "        df = apply_to_numberic_selective(df)\n",
    "    if using_xgboost:\n",
    "        df = process_column_names_xgboost(df)\n",
    "    df_merged = pd.merge(df,target_df, how='inner', left_index=True, right_index=True)\n",
    "    return df_merged\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def label_feature_split(df, column):\n",
    "    label=df[[column]].values.ravel()\n",
    "    feature=df.drop([column], axis=1)\n",
    "    return feature, label\n",
    "\n",
    "\n",
    "def metrics_regression(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Prints the standard of the metrics\n",
    "    :param y_test: the true labels of the test set\n",
    "    :param y_pred: the predicted labels of the test set\n",
    "    :return: None, this prints out the results of the metrics\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    MAE = median_absolute_error(y_test, y_pred)\n",
    "    RSE = mean_squared_error(y_test, y_pred)\n",
    "    sum_preds = y_pred.sum()\n",
    "    sum_actual = y_test.sum()\n",
    "    return r2, MAE, RSE, sum_preds, sum_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_generic_models_regression(X_train, y_train, X_test, y_test, reporter_object=None):\n",
    "    \n",
    "#     CBC = CatBoostRegressor(silent=True,task_type=\"GPU\")\n",
    "#     models = [(CBC, \"catboost regressor\")]\n",
    "    \n",
    "#     for model, name in models:\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         shap_values = shap.TreeExplainer(model).shap_values(X_train)\n",
    "#         shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "        \n",
    "#         print(y_test[:10])\n",
    "#         print(y_pred[:10])\n",
    "#         r2, MAE, RSE, sum_preds, sum_actual = metrics_regression(y_test, y_pred)\n",
    "        \n",
    "#         print('r2, MAE, RSE, sum_preds, sum_actual')\n",
    "#         print(r2, MAE, RSE, sum_preds, sum_actual)\n",
    "        \n",
    "#         plt.scatter(y_pred, y_test)\n",
    "#         plt.show()\n",
    "#         print(\"coeficient\")\n",
    "#         print(numpy.corrcoef(y_pred, y_test)[0, 1])\n",
    "#         return (numpy.corrcoef(y_pred, y_test)[0, 1])\n",
    "def analyse_generic_models_regression(X_train, y_train, X_test, y_test, reporter_object=None):\n",
    "    \n",
    "    \n",
    "    CBC = CatBoostRegressor(silent=True,task_type=\"GPU\")\n",
    "    \n",
    "    CBC.fit(X_train, y_train)\n",
    "    y_pred = CBC.predict(X_test)\n",
    "#     shap_values = shap.TreeExplainer(CBC).shap_values(X_train)\n",
    "#     shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "    X_test['actual_result']=y_test\n",
    "    X_test['predicted_result']=y_pred\n",
    "#     print(X_test['predicted_result'])\n",
    "#     print(X_test['actual_result'])\n",
    "    return X_test, numpy.corrcoef(y_pred, y_test)[0, 1]\n",
    "'''\n",
    "def analise_performance(X_train, y_train, X_test, y_test, reporter_object=None):\n",
    "   \n",
    "    CBC = CatBoostRegressor(silent=True,task_type=\"GPU\")\n",
    "    model = CBC\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    df = pd.DataFrame()\n",
    "    df['prediction']=y_pred\n",
    "    df['id'] = X_test.index.values   \n",
    "    return df\n",
    "'''\n",
    "def split_dataset(df, dataset):\n",
    "    \n",
    "    test_df = df[df[\"['test_dataset']_\"+dataset]==1]\n",
    "    train_df = df[df[\"['test_dataset']_\"+dataset]!=1]\n",
    "    return train_df, test_df\n",
    "\n",
    "def drop_bad_columns(df, columns=None):\n",
    "    if columns is not None:\n",
    "        return df.drop(columns, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with section 0.1\n",
      "coeficients\n",
      "0.9709843620082973\n",
      "0.9653300982187403\n",
      "0.9494013704445602\n",
      "0.8859975707197832\n",
      "0.9679981056255282\n",
      "0.9965392495457951\n",
      "0.9980266797396772\n",
      "0.9705593122740719\n",
      "0.9992375254528125\n",
      "0.9971159017544045\n",
      "0.9889432583348321\n",
      "klenditau output\n",
      "0.9999999999999999\n",
      "0.8666666666666666\n",
      "0.7777777777777777\n",
      "0.8666666666666666\n",
      "0.8222222222222221\n",
      "0.911111111111111\n",
      "0.6444444444444444\n",
      "0.6888888888888888\n",
      "0.8666666666666666\n",
      "0.911111111111111\n",
      "0.8666666666666666\n",
      "section completed\n"
     ]
    }
   ],
   "source": [
    "datasets_sections=[0.5,1,1.5,2]\n",
    "datasets_sections=[0.1]\n",
    "for selected_section in datasets_sections:\n",
    "    print('starting with section '+str(selected_section))\n",
    "    correlation_coeficient=[]\n",
    "    window=selected_section\n",
    "    dataset='friedman_10_noise_'+str(selected_section)+'_window_size_2'\n",
    "    directory='toy_datasets/ran_datasets/'+dataset+'.csv'\n",
    "    dataset_names=dataset+'_seed_'\n",
    "    numpy.random.seed(42)\n",
    "    dataset = pd.read_csv(directory)\n",
    "    target='MAE'\n",
    "    processed_features_df = preprocessing(dataset, target, bad_columns=['MSE','r2','mean','actual_sum'],using_xgboost=False)\n",
    "    \n",
    "    klenditau_results=[]\n",
    "    coeficient_results=[]\n",
    "    for i in range(11):\n",
    "        train_df, validation_df = split_dataset(processed_features_df,dataset_names+str(i))\n",
    "        X_train, y_train = label_feature_split(train_df,target)\n",
    "        X_validation, y_validation = label_feature_split(validation_df, target)\n",
    "        analyse_df, correlation_coeficient=analyse_generic_models_regression(X_train, y_train, X_validation, y_validation)\n",
    "\n",
    "        analyse_df = analyse_df.sort_values(by=['predicted_result'])\n",
    "        analyse_df['predicted_rankings']=analyse_df.reset_index().index.values\n",
    "        analyse_df = analyse_df.sort_values(by=['actual_result'])\n",
    "        analyse_df['actual_rankings']=analyse_df.reset_index().index.values\n",
    "        coeficient_results.append(correlation_coeficient)\n",
    "        klenditau_results.append(kendalltau(analyse_df['predicted_rankings'],analyse_df['actual_rankings'])[0])\n",
    "\n",
    "    print('coeficients')\n",
    "    for coeficient in coeficient_results:\n",
    "        print(coeficient)\n",
    "    print('klenditau output')\n",
    "    for klenditau_output in klenditau_results:\n",
    "        print(klenditau_output)\n",
    "    print('section completed')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
